#  Neural Network Forward Pass Implementation

## Course Information
* [cite_start]**Course:** Artificial Intelligence [cite: 3]
* [cite_start]**Assessment Type:** Implementation Task [cite: 5]
* [cite_start]**Theme:** Understanding Neural Network Computation [cite: 7, 8]

## Objective
[cite_start]The objective of this assessment is to demonstrate a conceptual understanding of how a neural network processes input data during a forward pass[cite: 10]. [cite_start]The focus is strictly on the computation flow, excluding training, optimization, or backpropagation[cite: 11, 20].

## Implementation Details
[cite_start]As per the guidelines[cite: 21], this program implements:
* [cite_start]**Input Layer:** Receives the initial data values[cite: 30].
* [cite_start]**Hidden Layer:** At least one layer with hardcoded weights and biases[cite: 27, 31].
* [cite_start]**Output Layer:** Computes the final result[cite: 32].
* [cite_start]**Activation Functions:** Utilizes ReLU for the hidden layer and Sigmoid for the output layer to demonstrate data transformation[cite: 18, 28].

## Mathematical Flow
The implementation clearly demonstrates:
1. [cite_start]How input values move through the layers[cite: 16].
2. [cite_start]How weights and biases are applied to calculate the "Net" values[cite: 17].
3. [cite_start]How activation functions are applied to produce the final outputs[cite: 18, 19].

## How to Run
1. [cite_start]Ensure you have **Python** installed[cite: 23].
2. Run the script using the following command:
   ```bash
   python nlu.py
